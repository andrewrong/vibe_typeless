# ⚠️  Docker 部署性能警告 (macOS Apple Silicon)
#
# macOS Docker 容器运行在 Linux VM 中，有以下限制：
#   ❌ 无法访问 macOS GPU/神经引擎（约 40% 性能损失）
#   ⚠️  资源限制会进一步降低性能
#   ✅ 如需最佳性能，请使用本地部署：./start.sh
#
# 性能对比（35 秒音频转录）：
#   - 本地部署: 5-8 秒 (100% 性能)
#   - Docker: 8-12 秒 (60-70% 性能)
#
# 推荐配置：
#   1. 开发/生产 → 本地部署 (./start.sh)
#   2. 测试/演示 → Docker 部署 (./docker-start.sh)
#
# 详见: PERFORMANCE.md

version: '3.8'

services:
  typeless-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: typeless-backend
    ports:
      - "28111:8000"
    environment:
      # AI Provider 配置
      - AI_PROVIDER=${AI_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}

      # 模型缓存目录
      - MODEL_CACHE_DIR=/app/models
      - HF_HOME=/app/models
      - WHISPER_CACHE_DIR=/app/models/whisper
      - HF_HUB_CACHE=/app/models/huggingface

      # 日志级别
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - RATE_LIMIT_ENABLED=${RATE_LIMIT_ENABLED:-true}

    volumes:
      # 模型文件持久化 - 避免每次重启都重新下载
      - ${MODEL_CACHE_PATH:-./models}:/app/models

      # 配置文件
      - ${PWD}/.env:/app/.env:ro

      # 日志目录
      - ${PWD}/logs:/app/logs

    restart: unless-stopped

    # 资源限制配置
    # ⚠️ macOS Docker 特殊说明：
    #   - Docker 容器运行在 Linux VM 中，无法直接访问 macOS GPU
    #   - MLX 会自动使用 CPU，性能约为本地运行的 60-70%
    #   - 如果需要最佳性能，建议使用本地部署（./start.sh）
    #   - 下面的限制仅影响容器内的资源，不影响宿主机
    #
    # 推荐配置（Apple Silicon）：
    #   - 移除所有限制以获得最佳性能
    #   - 或设置宽松的限制（保留以下配置）
    deploy:
      resources:
        limits:
          cpus: '8'      # CPU 限制（8核 = 无限制，即使用所有性能核心）
          memory: 16G   # 内存限制（根据你的机器调整）
        reservations:
          cpus: '4'     # 保留资源（确保最小性能）
          memory: 8G    # 保留内存

    # 健康检查
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    networks:
      - typeless-network

networks:
  typeless-network:
    driver: bridge

# 如果需要使用 Ollama，可以取消注释以下配置
# services:
#   ollama:
#     image: ollama/ollama:latest
#     container_name: ollama
#     ports:
#       - "11434:11434"
#     volumes:
#       - ollama_data:/root/.ollama
#     restart: unless-stopped
#
# volumes:
#   ollama_data:
